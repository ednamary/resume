<!DOCTYPE>
<html>
    <head>
        <title>
        Dipendra Shrestha Resume
        </title>
    </head>
    
        <body bgcolor="#CEF6F5">
        <div>
    <span><U>OBJECTIVE</U><br>
    Want to work in a field where the use of data analysis and data modelling is heavily dependent on scientific modeling, statistical and mathematical applications.
        </span>
        </div>
        <br>


        <div>
        <span><U>EDUCATION</U> <br>
        Master of Science, Business Analytics,<a href="https://www.csueastbay.edu">CSU East Bay, Hayward, CA</a> June/2017 <br>
        Bachelor of Science, Applied Mathematics, <a href="https://www.sjsu.edu">SJSU, San Jose, CA</a> June/2015
        </span>
        </div>
        <br>

     
        <div style="text-align: left">
        <span class="RELEVANT COURSEWORK"><U>RELEVANT COURSEWORK</U><br>
        Neural Network, Regression Modelling, Principal Component Analysis, K-means Clustering, Naïve Bayes Classification, Support Vector Machines, Bootstrapping, Statistical Analysis, Hypothesis Testing, Linear/Non-Linear Optimization, Data Visualization, Data Warehousing, Database Management, Tableau, Public Speaking, Philosophy
        </span>
        </div>
        <br>

        
        <div>
        <span class="TECHNICAL SKILLS1"><U>TECHNICAL SKILLS</U><br>
        Programming Language: Python, SQL, R</span><br>
        <span class="TECHNICAL SKILLS2">Software Tools: R-Studio, Erwin Data Modeler, Enterprise Architect, Oracle 11g Express, MS SQL Server Management Studio, Visual Studio 2015</span><br>
        <span class="TECHNICAL SKILLS3">MS Office: Excel, Word, PowerPoint, Access, VBA</span>
        </div>
        <br>

        <h><U>ACADEMIC PROJECTS</U></h>

        
        <div>
        <span class="Market Segmentation"><U>Market Segmentation</U><br>
        Downloaded the Social Networking Service data from Packt Publishing website with the filename snsdata.csv representing a random sample of 30,000 U.S. high school students. Conducted Exploratory Data Analysis on the dataset after saving it in a data-frame and discovered several missing values and out of range numerical values. Data cleaning was done on the age variable to get a more reasonable range of ages by using ifelse () function in R. Out of range values of age variable were turned into NA’s and combined with rest of NA’s. Data Imputation technique was employed to convert NA’s in age variable to its respective mean values rather than deleting all of it. Created a separate binary valued dummy variable for each level of Gender variable except one, which was kept for reference and NA’s were categorized under no_Gender dummy variable.Subset of the data frame was created by only including the 36 features that carried the high school students interest like basketball, sex, kissed, death, fashion etc. Z-score standardization was done to the newly created data frame with the use of scale () and lapply () function. 5 clusters were chosen based on the five stereotypes: a brain, an athlete, a basket case, a princess, and a criminal as these identities prevail throughout popular teen fiction. Implementation of k-means in the stats package was used to get a cluster object that stored the information about the clusters. Model was evaluated based on number of elements in the group and by examining whether the clusters fell above or below the mean level for each interest category. Five clusters were labelled as Princess, Brains, Criminals, Athletes and Basket Cases after inferring the characteristics of the clusters.
        </span>
        </div>
        <br>

        
        <div>
        <span class="Market Basket Analysis"><U>Market Basket Analysis</U><br>
        Downloaded the Groceries dataset in the arules R package that contain 9,835 transactions from one month of operation at areal-world grocery store.
        Converted the transactional data that is of free form to a sparse matrix form where each column represents a grocery item. Conducted Exploratory Data Analysis on the dataset to get information about the structure of the dataset in respect to the most frequent grocery items. Grocery item support – item frequency was visualized using itemFrequencyPlot () function with the support parameter. Groceryrules rules object was created using the implementation of the Apriori algorithm in the arules package with the appropriate support and confidence parameter value. Lift of 463 rules contained in the Groceryrules object were evaluated for model performance, as large lift is an indicator of an important rule. Inspect() function was used to look at specific rules in the groceryrules object that tells us the support, confidence and lift of a rule. Sort() function was combined with vector operators to obtain specific number of interesting rules so that the highest or lowest values of the quality measure come first. Subset() function was used to search for subsets of rules per the need of the marketing team so they can create an advertisement to promote product of interest.
        </span>
        </div>
        <br>

        
        <div>
        <span class="Data Visualization"><U>Data Visualization</U><br>
        Labor strike in different provinces of China was visualized using Tableau. Data from 2011/Jan – 2016/Dec was downloaded from http://maps.clb.org.hk/strikes/en for Beijing, Guangdong, Shanghai, and Chongqing. Variable Count was created for each row to denote for a strike Event. Variable Year was created from the Date variable of the Strike to do visualization by Year. Time Plot for each Province was created using Tableau. Plot of all four Provinces on the same time plot was created with each Province Represented by unique color. Dynamic bubble graph was also created using Tableau.
        </span>
        </div>
        <br>

        
        <div>
        <span class="Data warehouse"><U>Data warehouse</U><br>
        Designed a data warehouse for a hypothetical coffee company called Sun dusk that wanted to integrate IOT data to analyze its impact on sales. 
        (IOT: Internet of Things). Created a complete dimensional model (Schema) of 8 dimensions and a Fact table for sales business process keeping business users in mind so they could easily run different analysis. Product, Customer, Date, Employee, Store, Time of Day, Weather, Traffic were the 8 dimensions and Sales was the Fact Table. All the 8 dimensions’ primary keys were included in the Fact Table along with three measures: Unit Price, Quantity and Sales Amount. Erwin Data Modeler r9.7 was used for Logical/Physical implementation of the schema. Report 1: Sales across stores with varying cloud cover during the hours of 8:00 am – 4:00 pm and Months of May—Sep could be easily created. Report 2: Sales across products with varying temperature during the hours of 12:00 pm – 5:00 pm and Months of March—Sep could be easily created.
        </span>
        </div>
        <br>


        <div>
        <span class="Sentiment Analysis"><U>Sentiment Analysis</U><br>
        Downloaded the Arabic tweet data from UCI Machine Learning Repository that contained two separate datasets with each having 1000 files and each file containing a single tweet. Imported the whole dataset into Excel and randomized the tweets to classify as ‘Positive’ and ‘Negative’ randomly mixed. Conducted Exploratory Data Analysis on the dataset after saving it in a data-frame. Created training and test dataset with stratified sampling to guarantee random partitions with same proportions of each class in both sets of data. Applied Naïve Bayes algorithm to develop a statistical model and evaluated the model performance with accuracy of 73%.
        </span>
        </div>
        <br>

        
        <div>
        <span class="Breast Cancer Classification"><U>Breast Cancer Classification</U><br>
        Downloaded the Wisconsin Breast Cancer Diagnostic dataset from the UCI Machine Learning Repository at http://archive.ics.uci.edu.ml. Conducted Exploratory Data Analysis on the dataset to shine some light on the relationships among the variables. Created a normalize () function in R to normalize some numerical data to deploy k-NN algorithm which is heavily dependent upon the measurement scale of the input features. Created a training dataset to build the k-NN model and a test dataset to be used to estimate the predictive accuracy of the model. Used a k-NN implementation from the class package to build the classifier and evaluated the model performance using CrossTable () function in the gmodels package.
        </span>
        </div>
        <br>

        
        <div>
        <span><U>WORK EXPERIENCE</U><br>
        Sales Associate, Nordstrom, Inc.  | Palo Alto, CA   09/2007-12/2016<br>
        Performed physical counting of inventory, tagged merchandise, and updated inventory data.<br>
        Examined inventory for defects and damage and reported to department manager.<br>
        Prepared sales action plans and strategies.<br>
        Developed and maintained a customer database.<br>
        Planned and conducted direct marketing activities.<br>
        Recommended changes in product, service, and policy by evaluating results and competitive developments.<br>
        Resolved customer complaints by investigating problems; developing solutions; prepared reports; and made recommendations to management.<br>
        Recipient, “Pacesetter Award”, surpassed yearly goals: (2014 - $500K), (2011 and 2013 - $200K).<br>
        Recipient, “All Star Award”, for providing outstanding customer service.<br>
        </span>
        </div>

    </body>
</html>